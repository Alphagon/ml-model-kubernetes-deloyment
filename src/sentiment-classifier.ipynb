{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52375647-7493-49ef-a168-397b0f1ed782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:13:31.882141: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-22 20:13:31.885604: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-22 20:13:31.895145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-22 20:13:31.910917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-22 20:13:31.915523: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-22 20:13:31.927606: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-22 20:13:32.646542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, LSTM, Dense, Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a20f2-8907-49bb-ac72-628b2eb5d6ba",
   "metadata": {},
   "source": [
    "# Creating a simple model with no feature engineering. \n",
    "\n",
    "Just for inference and to create an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a385519e-f1fc-4b0b-9a38-e614ecce1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "max_features = 10000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a7dab2-3507-4805-8a83-518295cf38be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Train data\n",
      "25000 Test data\n",
      "train shape: (25000, 100)\n",
      "test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), \"Train data\")\n",
    "print(len(x_test), \"Test data\")\n",
    "\n",
    "# Padding data.\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print(\"train shape:\", x_train.shape)\n",
    "print(\"test shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e38c171-21bd-411d-b4aa-3e9f8d8c9272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721659416.330509  202746 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-22 20:13:36.335460: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 200))\n",
    "model.add(SimpleRNN(200, dropout=0.2, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed09525-0a04-43a3-a18a-464c81681bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - accuracy: 0.5971 - loss: 0.6934 - val_accuracy: 0.6768 - val_loss: 0.5651\n",
      "Epoch 2/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.7307 - loss: 0.5572 - val_accuracy: 0.6603 - val_loss: 0.5930\n",
      "Epoch 3/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.7889 - loss: 0.4513 - val_accuracy: 0.7922 - val_loss: 0.4673\n",
      "Epoch 4/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.8697 - loss: 0.3037 - val_accuracy: 0.8006 - val_loss: 0.4689\n",
      "Epoch 5/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9096 - loss: 0.2247 - val_accuracy: 0.7763 - val_loss: 0.5607\n",
      "Epoch 6/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9360 - loss: 0.1692 - val_accuracy: 0.7866 - val_loss: 0.5969\n",
      "Epoch 7/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9424 - loss: 0.1546 - val_accuracy: 0.7564 - val_loss: 0.7056\n",
      "Epoch 8/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.9563 - loss: 0.1201 - val_accuracy: 0.7850 - val_loss: 0.6564\n",
      "Epoch 9/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9584 - loss: 0.1132 - val_accuracy: 0.8034 - val_loss: 0.6923\n",
      "Epoch 10/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.9678 - loss: 0.0932 - val_accuracy: 0.7895 - val_loss: 0.7802\n",
      "Epoch 11/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9552 - loss: 0.1256 - val_accuracy: 0.7867 - val_loss: 0.9325\n",
      "Epoch 12/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9811 - loss: 0.0549 - val_accuracy: 0.7726 - val_loss: 0.8902\n",
      "Epoch 13/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9618 - loss: 0.1139 - val_accuracy: 0.7772 - val_loss: 0.8177\n",
      "Epoch 14/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9754 - loss: 0.0741 - val_accuracy: 0.7749 - val_loss: 0.9211\n",
      "Epoch 15/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9724 - loss: 0.0776 - val_accuracy: 0.7973 - val_loss: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f021d53ce80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=15, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc47ee2c-8b5f-4c36-bfd5-72ec8b10a9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7939 - loss: 1.0245\n",
      "Test score: 0.9872850775718689\n",
      "Test accuracy: 0.7973200082778931\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"Test score:\", score)\n",
    "print(\"Test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9d7769-d61f-4cfe-89f1-db133b42d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "if acc > 0.85:\n",
    "    model.save(\"sentiment-model.h5\")\n",
    "    print(\"model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de0a33-b5a2-46b0-8a44-b89d3c94d2be",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca0f694-80ca-4648-bc9c-056405dfa142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 10:19:25.160285: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-23 10:19:25.222676: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-23 10:19:25.284162: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 10:19:25.341448: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 10:19:25.357376: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 10:19:25.447359: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 10:19:26.383966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "max_len = 100\n",
    "max_features = 10000\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def preprocess_review(review, word_index, max_len):\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.word_index = word_index\n",
    "    sequences = tokenizer.texts_to_sequences([review])\n",
    "    \n",
    "    padded_sequence = sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4abc999-335e-46c4-b74b-fd9afcc2f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"sentiment-model.h5\")\n",
    "\n",
    "new_review = \"The plot good and the characters were interesting.\"\n",
    "preprocessed_review = preprocess_review(new_review, word_index, max_len)\n",
    "prediction = model.predict(preprocessed_review)\n",
    "predicted_label = (prediction > 0.5).astype(\"int32\")\n",
    "print(f\"Predicted sentiment: {'positive' if predicted_label[0][0] == 1 else 'negative'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ef3a3",
   "metadata": {},
   "source": [
    "Delete it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8efa016-bf7d-42d6-b1a7-641c37d5788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# from fastapi import FastAPI\n",
    "# from pydantic import BaseModel\n",
    "# from tensorflow.keras.preprocessing import sequence\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.datasets import imdb\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# #Parameters\n",
    "# max_len = 100\n",
    "# max_features = 10000\n",
    "\n",
    "# word_to_index = imdb.get_word_index()\n",
    "\n",
    "# model = load_model(\"sentiment-model.h5\")\n",
    "\n",
    "# def preprocess_review(review, word_to_index, max_len, max_features):\n",
    "#     tokenizer = Tokenizer(num_words=max_features)\n",
    "#     tokenizer.word_index = word_to_index\n",
    "#     sequence = tokenizer.texts_to_sequence([review])\n",
    "#     padded_sequence = sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "#     return padded_sequence\n",
    "\n",
    "# app = FastAPI(title=\"IMDB Sentiment classifier API\",\n",
    "#               version=\"0.1\")\n",
    "\n",
    "# class Review(BaseModel):\n",
    "#     text:str\n",
    "\n",
    "# # @app.post(\"/predict\")\n",
    "# def predict_sentiment(review: str):\n",
    "#     preprocessed_review = preprocess_review(review.txt, word_to_index, max_len, max_features)\n",
    "\n",
    "#     prediction = model.predict(preprocessed_review)\n",
    "#     predicted_label = (prediction > 0.5).astype(\"int32\")\n",
    "\n",
    "#     sentiment = 'positive' if predicted_label[0][0] == 1 else 'negative'\n",
    "\n",
    "#     return {\"Sentiment\": sentiment, \"Probability\": prediction}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Onelab",
   "language": "python",
   "name": "onelab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
